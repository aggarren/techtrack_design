{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb958d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "DATASET_IMAGES_DIR = \"C:/Users/agand/ObjectDetectionFiles//logistics\"\n",
    "MODEL1_NAMES_FILE = \"C:/Users/agand/ObjectDetectionFiles/yolo_model_1/logistics.names\"\n",
    "MODEL1_WEIGHTS = \"C:/Users/agand/ObjectDetectionFiles/yolo_model_1/yolov4-tiny-logistics_size_416_1.weights\"\n",
    "MODEL1_CFG = \"C:/Users/agand/ObjectDetectionFiles//yolo_model_1/yolov4-tiny-logistics_size_416_1.cfg\"\n",
    "MODEL2_NAMES_FILE = \"C:/Users/agand/ObjectDetectionFiles/yolo_model_2/logistics.names\"\n",
    "MODEL2_WEIGHTS = \"C:/Users/agand/ObjectDetectionFiles//yolo_model_2/yolov4-tiny-logistics_size_416_2.weights\"\n",
    "MODEL2_CFG = \"C:/Users/agand/ObjectDetectionFiles//yolo_model_2/yolov4-tiny-logistics_size_416_2.cfg\"\n",
    "IMG_SIZE = (416, 416)\n",
    "SCORE_THRESHOLD = 0.25\n",
    "NMS_THRESHOLD = 0.45\n",
    "OUTPUT_DIR = \"C:/Users/agand/ObjectDetectionFiles/outputs\"\n",
    "MODEL1_OUT = \"C:/Users/agand/ObjectDetectionFiles/outputs/model1\"\n",
    "MODEL2_OUT = \"C:/Users/agand/ObjectDetectionFiles/outputs/model2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ecd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os, glob, json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f751b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL1_OUT, exist_ok=True)  \n",
    "os.makedirs(MODEL2_OUT, exist_ok=True)\n",
    "IMAGES = glob.glob(os.path.join(DATASET_IMAGES_DIR, '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0feb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_model(cfgfile, weightfile,namesfile):\n",
    "    net = cv2.dnn.readNet(weightfile,cfgfile)\n",
    "    layers = net.getLayerNames()\n",
    "    output_layers = [layers[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "    with open(namesfile, 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    return net, output_layers, classes\n",
    "\n",
    "net1, layers1, classes1 = yolo_model(MODEL1_CFG, MODEL1_WEIGHTS,MODEL1_NAMES_FILE)\n",
    "net2, layers2, classes2 = yolo_model(MODEL2_CFG, MODEL2_WEIGHTS,MODEL2_NAMES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e857fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, net, output_layers):\n",
    "    image = cv2.imread(image_path)\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        image,\n",
    "        scalefactor=1/255.0,\n",
    "        size=IMG_SIZE,\n",
    "        mean=(0, 0, 0),\n",
    "        swapRB=True,\n",
    "        crop=False\n",
    "    )\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(output_layers)\n",
    "    detections = []\n",
    "    for feature_maps in outputs:\n",
    "        for detection in feature_maps:\n",
    "            boxes = detection[:4].tolist()\n",
    "            score = detection[4].tolist()\n",
    "            class_scores = detection[5:].tolist()\n",
    "            class_id = int(np.argmax(class_scores))\n",
    "            detections += [{\"image_path\":image_path,\"class_id\": class_id, \"score\": score, \"box\": boxes}]\n",
    "    return detections\n",
    "\n",
    "def get_ground_truth(image_path):\n",
    "    gt_txt = os.path.splitext(image_path)[0] + \".txt\"\n",
    "    ground_truth = []\n",
    "    if not os.path.exists(gt_txt):\n",
    "        return ground_truth \n",
    "\n",
    "    with open(gt_txt, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            cls = int(parts[0])\n",
    "            ground_truth.append({\n",
    "                \"class_id\": cls,\n",
    "                \"box\": parts[1:5]\n",
    "            })\n",
    "    return ground_truth\n",
    "\n",
    "\n",
    "def save_prediction_json(img_path,model,detections,output_json):\n",
    "    json_data = {\n",
    "        \"image_path\": img_path,\n",
    "        \"model\":model,\n",
    "        \"predictions\": detections,\n",
    "        \"ground_truth\": get_ground_truth(img_path)\n",
    "    }\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(json_data, f, indent=4)\n",
    "\n",
    "for img_path in IMAGES:\n",
    "    detections1 = predict_image(img_path, net1, layers1)\n",
    "    detections2 = predict_image(img_path, net2, layers2)\n",
    "    \n",
    "    output_json1 = os.path.join(MODEL1_OUT, os.path.basename(img_path).replace('.jpg', '_predictions.json'))\n",
    "    output_json2 = os.path.join(MODEL2_OUT, os.path.basename(img_path).replace('.jpg', '_predictions.json'))\n",
    "\n",
    "    save_prediction_json(img_path,\"model_1\",detections1,output_json1)\n",
    "    save_prediction_json(img_path,\"model_2\",detections2,output_json2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8db56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
